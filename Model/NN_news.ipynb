{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, GlobalMaxPool1D, Conv1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary’s Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"news.csv\")\n",
    "df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    FAKE\n",
       "1    FAKE\n",
       "2    REAL\n",
       "3    FAKE\n",
       "4    REAL\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df['label']\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Daniel Greenfield, a Shillman Journalism Fello...\n",
       "1       Google Pinterest Digg Linkedin Reddit Stumbleu...\n",
       "2       U.S. Secretary of State John F. Kerry said Mon...\n",
       "3       — Kaydee King (@KaydeeKing) November 9, 2016 T...\n",
       "4       It's primary day in New York and front-runners...\n",
       "                              ...                        \n",
       "6330    The State Department told the Republican Natio...\n",
       "6331    The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "6332     Anti-Trump Protesters Are Tools of the Oligar...\n",
       "6333    ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "6334    Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "Name: text, Length: 6335, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['text']\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  text, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accounting for text of different length\n",
    "max_len = 500\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,  135,   29,  809,    5,  542,\n",
       "       1892,    9,   23,  461, 1710,  360, 2869, 3916,   43,    3,    1,\n",
       "       3414,    6,  220,    3,  461], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
    "  GlobalMaxPool1D(),\n",
    "  Flatten(),\n",
    "  Dense(10, activation=\"relu\"),\n",
    "  Dense(1, 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=\"binary_crossentropy\",\n",
    "  metrics=['accuracy'],\n",
    "  optimizer=\"adam\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 500, 50)           4395150   \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 50)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,395,671\n",
      "Trainable params: 4,395,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "159/159 [==============================] - 12s 71ms/step - loss: 0.6542 - accuracy: 0.7701 - val_loss: 0.5584 - val_accuracy: 0.8674\n",
      "Epoch 2/20\n",
      "159/159 [==============================] - 10s 63ms/step - loss: 0.3934 - accuracy: 0.8887 - val_loss: 0.2710 - val_accuracy: 0.9053\n",
      "Epoch 3/20\n",
      "159/159 [==============================] - 10s 65ms/step - loss: 0.2166 - accuracy: 0.9240 - val_loss: 0.2026 - val_accuracy: 0.9179\n",
      "Epoch 4/20\n",
      "159/159 [==============================] - 13s 80ms/step - loss: 0.1489 - accuracy: 0.9509 - val_loss: 0.1797 - val_accuracy: 0.9211\n",
      "Epoch 5/20\n",
      "159/159 [==============================] - 14s 86ms/step - loss: 0.1051 - accuracy: 0.9716 - val_loss: 0.1736 - val_accuracy: 0.9250\n",
      "Epoch 6/20\n",
      "159/159 [==============================] - 11s 66ms/step - loss: 0.0750 - accuracy: 0.9807 - val_loss: 0.1677 - val_accuracy: 0.9227\n",
      "Epoch 7/20\n",
      "159/159 [==============================] - 9s 60ms/step - loss: 0.0529 - accuracy: 0.9901 - val_loss: 0.1678 - val_accuracy: 0.9266\n",
      "Epoch 8/20\n",
      "159/159 [==============================] - 10s 66ms/step - loss: 0.0369 - accuracy: 0.9933 - val_loss: 0.1707 - val_accuracy: 0.9266\n",
      "Epoch 9/20\n",
      "159/159 [==============================] - 10s 65ms/step - loss: 0.0252 - accuracy: 0.9963 - val_loss: 0.1743 - val_accuracy: 0.9282\n",
      "Epoch 10/20\n",
      "159/159 [==============================] - 10s 65ms/step - loss: 0.0177 - accuracy: 0.9988 - val_loss: 0.1759 - val_accuracy: 0.9258\n",
      "Epoch 11/20\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 0.0121 - accuracy: 0.9998 - val_loss: 0.1812 - val_accuracy: 0.9250\n",
      "Epoch 12/20\n",
      "159/159 [==============================] - 10s 61ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9266\n",
      "Epoch 13/20\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9266\n",
      "Epoch 14/20\n",
      "159/159 [==============================] - 10s 61ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9274\n",
      "Epoch 15/20\n",
      "159/159 [==============================] - 10s 61ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9266\n",
      "Epoch 16/20\n",
      "159/159 [==============================] - 11s 71ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9274\n",
      "Epoch 17/20\n",
      "159/159 [==============================] - 10s 63ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9266\n",
      "Epoch 18/20\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9258\n",
      "Epoch 19/20\n",
      "159/159 [==============================] - 11s 66ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9266\n",
      "Epoch 20/20\n",
      "159/159 [==============================] - 10s 60ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9250\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  X_train, y_train,\n",
    "  epochs=20,\n",
    "  validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8df71d7f3ee6b5c4895fa0a092f36c0c32600308d0bab5cd17897624831d76d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
